version: '3.8'

# IntelliOptics 2.0 - Edge Deployment
# Lightweight, nginx-based edge inference with detector-centric architecture

services:
  nginx:
    build: ./nginx
    container_name: intellioptics-edge-nginx
    ports:
      - "30101:30101"  # Main edge endpoint (matches diagram)
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      edge-api:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - edge-net

  edge-api:
    build: ./edge-api
    container_name: intellioptics-edge-api
    ports:
      - "8718:8718"  # Edge Endpoint port (matches diagram)
    environment:
      - INTELLIOPTICS_API_TOKEN=${INTELLIOPTICS_API_TOKEN:-}
      - UPSTREAM_CLOUD_API=${UPSTREAM_CLOUD_API:-https://intellioptics-api-37558.azurewebsites.net}
      - POSTGRES_DSN=${POSTGRES_DSN:-}
      - MODEL_REPOSITORY_PATH=/models
      - INFERENCE_SERVICE_URL=http://inference:8001
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - DEPLOY_DETECTOR_LEVEL_INFERENCE=0  # No K8s dynamic pods
      - RTSP_USER=${RTSP_USER:-}
      - RTSP_PASS=${RTSP_PASS:-}
      - PORT=8718
    volumes:
      - ./config:/config:ro
      - models:/models
      - edge_data:/data
    depends_on:
      inference:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8718/health/live"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 30s
    restart: unless-stopped
    networks:
      - edge-net

  inference:
    build: ./inference
    container_name: intellioptics-inference
    ports:
      - "8001:8001"  # Inference service port
    environment:
      - MODEL_REPOSITORY=/models
      - INTELLIOPTICS_API_TOKEN=${INTELLIOPTICS_API_TOKEN}
      - CLOUD_MODEL_API=${UPSTREAM_CLOUD_API}/edge-api/v1/fetch-model-urls
      - IO_IMG_SIZE=640
      - IO_CONF_THRESH=0.25
      - IO_NMS_IOU=0.45
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
    volumes:
      - models:/models
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 10s
      timeout: 3s
      retries: 3
      start_period: 60s  # Models take time to load
    restart: unless-stopped
    networks:
      - edge-net
    # Uncomment for GPU support
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1
    #           capabilities: [gpu]

  postgres:
    image: postgres:15-alpine
    container_name: intellioptics-edge-db
    environment:
      - POSTGRES_USER=intellioptics
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-intellioptics}
      - POSTGRES_DB=intellioptics
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U intellioptics"]
      interval: 5s
      timeout: 3s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    networks:
      - edge-net
    # Optional: Disable if not using DB on edge
    # Comment out this service to run without local database

volumes:
  models:
    driver: local
  edge_data:
    driver: local
  postgres_data:
    driver: local
  nginx_logs:
    driver: local

networks:
  edge-net:
    driver: bridge
    name: intellioptics-edge-network
